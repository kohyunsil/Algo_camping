from tqdm import tqdm
from bs4 import BeautifulSoup
import requests
from urllib.request import Request, urlopen
import xmltodict
import json
from pandas.io.json import json_normalize
import pandas as pd
import re
from datetime import datetime
import pymysql
from sqlalchemy import create_engine

pymysql.install_as_MySQLdb()
# import camping_server2.config as config

class Gocamp:
    base_url = "https://www.gocamping.or.kr"
    path = "/bsite/camp/info/list.do"
    query = "?pageUnit=3000&searchKrwd=&listOrdrTrget=last_updusr_pnttm"
    url = base_url + path + query

    def __init__(self):
        self.secretKey = " "
   
    # gocamp crawling
    def fetch_link_list(self):
        print("ğŸ‘‰ Start fetch camp list")
        response = requests.get(self.url)
        dom = BeautifulSoup(response.content, "html.parser")
        items = dom.select("#cont_inner > div > div.camp_search_list > ul > li")

        rows = []

        for item in items:
            new_row = {
                "title": item.select_one("h2 > a").text,
                "description": item.select_one(".camp_stt").text,
                "address": item.select_one(".addr").text,
                # "contact": item.select_one("ul > li.call_num"),
                # "facility": item.select_one('i > span'),
                "view": item.select_one('div > div > p > span.item_t03').text,
                "link": "https://www.gocamping.or.kr" + item.select_one("div > a").get("href"),
                "tags": "",
                # "info": "",
                # "etc": "",
                "img_url": "",
                # "price": ""
            }
            rows.append(new_row)

        list_df = pd.DataFrame(rows)
        return list_df

    def fetch_link_details(self, list_df):
        list_df = list_df[:10]
        df = list_df.fillna('')
        for idx in tqdm(df.index):
            link = df.loc[idx, 'link']
            response = requests.get(link)
            dom = BeautifulSoup(response.text, "html.parser")
            # info = dom.select_one("table > tbody").text.strip()
            # info = info.replace("\t", " ").replace("\n", " ")
            # etc_info = dom.select_one("#table_type03 > div > table > tbody").text.strip()
            # etc_info = etc_info.replace("\t", " ").replace("\n", " ")
            imgs = dom.select('#contents > div > div.layout > div > div > div > a > img')
            #
            for img in imgs:
                df.loc[idx,"img_url"] = df.loc[idx,"img_url"] + str(img["src"]) + ","
            
            try:
                tags = dom.select_one("div.camp_tag > ul.tag_list").text.strip().replace("\n", " ")
            except:
                pass
            # pay_link = "https://www.gocamping.or.kr" + dom.select_one('#c_guide > a').get("href")

            df["tags"][idx] = tags
        #     # self.df["info"][idx] = info
        #     # self.df["etc"][idx] = etc_info
            # df["img_url"][idx] = img_url
        df["img_url"].str.split(",", expand=True)
        return df
    
    # gocamp API
    def gocampingAPI(self):
        url = 'http://api.visitkorea.or.kr/openapi/service/rest/GoCamping/basedList?'
        param = 'ServiceKey='+self.secretKey+'&MobileOS=ETC&MobileApp=AppTest&numOfRows=3000'

        request = Request(url+param)
        request.get_method = lambda: 'GET'
        response = urlopen(request)
        rescode = response.getcode()

        if rescode == 200:
            responseData = response.read()
            rD = xmltodict.parse(responseData)
            rDJ = json.dumps(rD)
            rDD = json.loads(rDJ)

            camp_api_df = json_normalize(rDD['response']['body']['items']['item'])
            return camp_api_df

    def make_camp_api(self, camp_api_df):
        camp = camp_api_df.drop(['allar', 'siteMg1Co', 'siteMg1Vrticl', 'siteMg1Width', 'siteMg2Co', 'siteMg2Vrticl', 
                'siteMg2Width', 'siteMg3Co', 'siteMg3Vrticl', 'siteMg3Width', 'zipcode', 'resveCl', 'resveUrl',
                'intro', 'direction', 'featureNm', 'hvofBgnde', 'hvofEnddle', 'tooltip'], 1) 
        camp = camp.rename(columns={'addr1' : 'addr',
                        'animalCmgCl' : 'animal_cmg',
                        'autoSiteCo' : 'auto_site',
                        'brazierCl' : 'brazier',
                        'caravAcmpnyAt' : 'carav_acmpny',
                        'caravSiteCo' : 'carav_site',
                        'clturEventAt' : 'clturevent_at',
                        'contentId' : 'content_id',
                        'createdtime' : 'created_date',
                        'exprnProgrmAt' : 'exprnprogrm_at',
                        'extshrCo' : 'extshr',
                        'facltNm' : 'place_name',
                        'fireSensorCo' : 'firesensor',
                        'frprvtSandCo' : 'frprvtsand',
                        'frprvtWrppCo' : 'frprvtwrpp',
                        'glampSiteCo' : 'glamp_site',
                        'gnrlSiteCo' : 'gnrl_site', 
                        'induty' : 'industry',
                        'indvdlCaravSiteCo' : 'indvdlcarav_site',
                        'insrncAt' : 'insrnc_at',
                        'manageNmpr' : 'manage_num',
                        'manageSttus' : 'manage_sttus',
                        'mangeDivNm' : 'mange',
                        'mapX' : 'lat', 
                        'mapY' : 'lng',                     
                        'modifiedtime' : 'modified_date',
                        'operDeCl' : 'oper_date',
                        'operPdCl' : 'oper_pd',
                        'prmisnDe' : 'prmisn_date',
                        'siteBottomCl1' : 'site_bottom1',
                        'siteBottomCl2' : 'site_bottom2',
                        'siteBottomCl3' : 'site_bottom3',
                        'siteBottomCl4' : 'site_bottom4',
                        'siteBottomCl5' : 'site_bottom5',
                        'sitedStnc' : 'sited_stnc',
                        'swrmCo' : 'swrm_cnt',
                        'toiletCo' : 'toilet_cnt',
                        'trlerAcmpnyAt' : 'trler_acmpny',
                        'wtrplCo' : 'wtrpl_cnt',
                        'clturEvent' : 'clturevent',
                        'eqpmnLendCl' : 'eqpmn_lend',
                        'firstImageUrl' : 'first_image',
                        'posblFcltyCl' : 'posblfclty',
                        'posblFcltyEtc' : 'posblfclty_etc',
                        'sbrsCl' : 'sbrs',
                        'sbrsEtc' : 'sbrs_etc', 
                        'themaEnvrnCl' : 'thema_envrn',
                        'tourEraCl' : 'tour_era',
                        'lctCl' : 'lct',
                        'facltDivNm' : 'faclt_div',
                        'lineIntro' : 'line_intro',
                        'trsagntNo' : 'trsagnt_no', 
                        'mgcDiv' : 'mgc_div',
                        'glampInnerFclty' : 'glampinner_fclty',
                        'caravInnerFclty' : 'caravinner_fclty',
                        'sigungucode' : 'sigungu_code',
                        'exprnProgrm' : 'exprnprogrm',
                        })
        camp['place_num'] = 0 
        return camp

    def make_camp_crawling(self, data) :
        camp_details = data.rename(columns={'view' : 'readcount'})
        camp_details['readcount'] = camp_details['readcount'].str.split(' ').str[1]
        datas = camp_details['link']
        data = [re.findall("\d+",data)[0] for data in datas]
        camp_details['url_num'] = data
        return camp_details

    def merge_data(self, camp, camp_details):
        merge_data = pd.merge(camp, camp_details, how='right', left_on='content_id', right_on='url_num')
        merge_data = merge_data.drop(['title', 'address'], 1)
        camp_df = merge_data.dropna(subset = ['addr'])
        camp_df = camp_df.reset_index().reset_index()
        camp_df = camp_df.drop(['index'],1)
        camp_df = camp_df.rename(columns={'level_0' : 'place_id', 
                                    'img_url' : 'detail_image', 
                                    'tags' : 'tag',
                                    'view' : 'readcount', 
                                    })
        camp_df
        return camp_df

class Sigungucode:
    def __init__(self):
        self.do_list = {'ì¶©ë¶': 'ì¶©ì²­ë¶ë„', 'ì¶©ë‚¨': 'ì¶©ì²­ë‚¨ë„',
               'ê²½ë¶': 'ê²½ìƒë¶ë„', 'ê²½ë‚¨': 'ê²½ìƒë‚¨ë„',
               'ì „ë¶': 'ì „ë¼ë¶ë„', 'ì „ë‚¨': 'ì „ë¼ë‚¨ë„',
               'ê°•ì›': 'ê°•ì›ë„', 'ê²½ê¸°': 'ê²½ê¸°ë„',
               'ì¸ì²œ': 'ì¸ì²œê´‘ì—­ì‹œ', 'ì¸ì²œì‹œ': 'ì¸ì²œê´‘ì—­ì‹œ',
               'ë¶€ì‚°': 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ìš¸ì‚°': 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ëŒ€ì „': 'ëŒ€ì „ê´‘ì—­ì‹œ',
               'ëŒ€êµ¬': 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ê´‘ì£¼': 'ê´‘ì£¼ê´‘ì—­ì‹œ',
               'ì„œìš¸': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ì„œìš¸ì‹œ': 'ì„œìš¸íŠ¹ë³„ì‹œ',
               'ì œì£¼': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼ë„': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'}


    def do_sigungu(self, df):
        df = df.drop(df[df['addr1'].isnull()].index, axis=0) # ë¹ˆ row ì‚­ì œ
        # ì˜ˆì™¸ì²˜ë¦¬ 1: í˜ìŠ¤í‹°ë°œ ì˜¨ë¼ì¸ê°œìµœ ì‚­ì œ
        try:
            df = df.drop(df[df['addr1'] == 'ì˜¨ë¼ì¸ê°œìµœ'].index, axis=0)
        except:
            pass

        # ë„, ì‹œêµ°êµ¬ëª… ì»¬ëŸ¼ ìƒì„±
        if not 'doNm' in df.columns.tolist():
            df['doNm'] = [a.split(" ")[0] for a in df['addr1']]
            df['doNm'] = [as_is.replace(as_is, self.do_list[as_is]) if len(as_is) < 3 else as_is for as_is in df['doNm']]
        if not 'sigunguNm' in df.columns.tolist():
            df['sigunguNm'] = [b.split(" ")[1:2] for b in df['addr1']]
            df['sigunguNm'] = [b[0] if len(b) > 0 else "" for b in df['sigunguNm']]

        df['sigunguNm2'] = [c.split(" ")[1:3] for c in df['addr1']]
        df['sigunguNm2'] = [c[0] + " " + c[1] if len(c) > 1 else "" for c in df['sigunguNm2']]
        df['sigunguNm3'] = [c.split(" ")[0:2] for c in df['addr1']]
        df['sigunguNm3'] = [c[0] + " " + c[1] if len(c) > 1 else "" for c in df['sigunguNm3']]

        # ì˜ˆì™¸ì²˜ë¦¬ 2: sigunguNm nullê°’ ì²˜ë¦¬
        sigunguNm = []
        for i in range(len(df)):
            a = df['sigunguNm'].iloc[i]
            b = df['sigunguNm2'].iloc[i]
            if type(a) == float:  # sigunguNm nullê°’ ì˜ˆì™¸ì²˜ë¦¬
                result = b.split(" ")[0]
            else:
                result = a
            sigunguNm.append(result)
        df['sigunguNm'] = sigunguNm

        return df


    def make_sigungucode(self, df):
        df = self.do_sigungu(df)
        cursor.execute('SELECT * FROM sigungucode')
        query = cursor.fetchall()
        five_code = pd.DataFrame(data=query)
        # ì¡°ê±´ì— ë§ê²Œ ì‹œêµ°êµ¬ì½”ë“œ ìƒì„±
        signguNm_ls = five_code['signguNm'].unique().tolist()
        sigungucode = []

        for i in range(len(df)):
            a = df['sigunguNm'].iloc[i]
            b = df['sigunguNm2'].iloc[i]
            c = df['sigunguNm3'].iloc[i]
            d = df['doNm'].iloc[i]
            if a in signguNm_ls:
                result = five_code['signguCode'][five_code['signguNm'] == a].iloc[0]
            elif b in signguNm_ls:
                result = five_code['signguCode'][five_code['signguNm'] == b].iloc[0]
            elif c in signguNm_ls:
                result = five_code['signguCode'][five_code['signguNm'] == c].iloc[0]
            elif d in ['ì„¸ì¢…ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ']:
                result = five_code['signguCode'][five_code['signguNm'] == 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'].iloc[0]
            else:
                result = 'í™•ì¸í•„ìš”'
            sigungucode.append(result)

        # ì‹œêµ°êµ¬ì½”ë“œ ì»¬ëŸ¼ ìƒì„±
        df['sigungucode'] = sigungucode

        # DB ì €ì¥ì‹œ í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì‚­ì œ
        df.drop(['doNm', 'sigunguNm', 'sigunguNm2', 'sigunguNm3'], axis=1, inplace=True)

        return df
        
    
# merge_data ë„£ê³  ê·¸ë‹¤ìŒì— ë‹¤ì‹œ ê°€ì ¸ì™€ì„œ idê°’ìœ¼ë¡œ place_id ë§Œë“¤ì–´ì•¼í•¨
class PlaceSubTable():
    def place_table(self,camp_df):
        place_df = camp_df[['place_id', 'place_num', 'place_name',  'addr', 'lat', 'lng', 
                'first_image','tel', 'addr2', 'thema_envrn', 'tour_era', 
                'homepage', 'line_intro', 'created_date', 'modified_date', 'detail_image', 'tag', 'readcount', 
                'content_id', 'industry', 'oper_date', 'oper_pd',]]
        place_df = place_df.rename(columns={'place_id' : 'id'})
        return place_df
    
    # convenience table
    def convenience_table(self, camp_df):
        convenience_df = camp_df[['place_id','sited_stnc', 'brazier', 'site_bottom1', 'site_bottom2', 'site_bottom3', 
                                            'site_bottom4', 'site_bottom5', 'swrm_cnt', 'toilet_cnt', 'wtrpl_cnt', 'sbrs', 'sbrs_etc', 
                                            'eqpmn_lend']]
        return convenience_df
    
    # operation table
    def operation_table(self, camp_df):
        operation_df = camp_df[['place_id', 'mange', 'manage_sttus', 'prmisn_date', 'faclt_div', 'trsagnt_no', 
                                        'mgc_div', 'bizrno']]
        return operation_df
    
    # variety table
    def variety_table(self, camp_df):
        variety_df = camp_df[['place_id', 'glamp_site', 'gnrl_site', 'indvdlcarav_site', 'carav_site', 'auto_site', 
                                    'carav_acmpny', 'trler_acmpny', 'lct', 'animal_cmg', 'clturevent_at', 
                                    'exprnprogrm_at', 'clturevent', 'posblfclty', 'posblfclty_etc', 'glampinner_fclty', 
                                    'caravinner_fclty', 'exprnprogrm']]
        return variety_df
    
    # safety table
    def safety_table(self, camp_df):
        safety_df = camp_df[['place_id', 'insrnc_at', 'manage_num', 'extshr', 'firesensor', 'frprvtsand', 'frprvtwrpp']]
        return safety_df


class AlgorithmTable():
    def __init__(self):
        self.category = {'ì¬ë¯¸ìˆëŠ”' : 'ì¦ê¸¸ê±°ë¦¬',
            'ì˜¨ìˆ˜ ì˜ ë‚˜ì˜¤ëŠ”' : 'ì¾Œì /í¸ë¦¬',
            'ì•„ì´ë“¤ ë†€ê¸° ì¢‹ì€' : 'í•¨ê»˜',
            'ìƒíƒœêµìœ¡' : 'ì¦ê¸¸ê±°ë¦¬',
            'ê°€ì¡±' : 'í•¨ê»˜',
            'ì¹œì ˆí•œ' : 'ì¾Œì /í¸ë¦¬',
            'ì—¬ìœ ìˆëŠ”' : 'ìì—°/íë§',
            'ê¹¨ë—í•œ' : 'ì¾Œì /í¸ë¦¬',
            'ê³„ê³¡ ì˜†' : 'ìì—°/íë§',
            'ë¬¼ë†€ì´ í•˜ê¸° ì¢‹ì€' : 'ì•¡í‹°ë¹„í‹°',
            'ë¬¼ë§‘ì€' : 'ìì—°/íë§',
            'ë‘˜ë ˆê¸¸' : 'ì¦ê¸¸ê±°ë¦¬',
            'ë³„ë³´ê¸° ì¢‹ì€' : 'ìì—°/íë§',
            'íë§' : 'ìì—°/íë§',
            'ì»¤í”Œ' : 'í•¨ê»˜',
            'ì°¨ ëŒ€ê¸° í¸í•œ' : 'ì¾Œì /í¸ë¦¬',
            'ì‚¬ì´íŠ¸ ê°„ê²©ì´ ë„“ì€' : 'ì¾Œì /í¸ë¦¬',
            'ì¶•ì œ' : 'ì¦ê¸¸ê±°ë¦¬',
            'ë¬¸í™”ìœ ì ' : 'ì¦ê¸¸ê±°ë¦¬',
            'ìì „ê±° íƒ€ê¸° ì¢‹ì€' : 'ì•¡í‹°ë¹„í‹°',
            'ê·¸ëŠ˜ì´ ë§ì€' : 'ìì—°/íë§',
            'ìˆ˜ì˜ì¥ ìˆëŠ”' : 'ì•¡í‹°ë¹„í‹°',
            'ë°”ë‹¤ê°€ ë³´ì´ëŠ”' : 'ìì—°/íë§',
            'ìµìŠ¤íŠ¸ë¦¼' : 'ì•¡í‹°ë¹„í‹°',
            'ë°˜ë ¤ê²¬' : 'í•¨ê»˜'}

    def tag_stack(self, camp_df):
        camping_data = camp_df[['place_id', 'content_id', 'place_name', 'addr', 'tag', 'animal_cmg']]
        camping_data['tag'] = camping_data['tag'].fillna("")
        camping_data["tag"][camping_data["animal_cmg"] == "ê°€ëŠ¥"] = camping_data[camping_data["animal_cmg"] == "ê°€ëŠ¥"]["tag"] + "#ë°˜ë ¤ê²¬"
        camping_data["tag"][camping_data["animal_cmg"] == "ê°€ëŠ¥(ì†Œí˜•ê²¬)"] = camping_data[camping_data["animal_cmg"] == "ê°€ëŠ¥(ì†Œí˜•ê²¬)"]["tag"] + "#ë°˜ë ¤ê²¬"

        lookup = pd.DataFrame(columns=["sub_cat", "main_cat"], data=self.category)
        lookup['sub_cat'] = lookup['sub_cat'].str.replace(" ","")
        lookup['main_cat'] = lookup['main_cat'].str.replace(" ","")
        lookup['main_cat'] = lookup['main_cat'].str.replace(" ","")
        camping_data['tag'] = [t[:] if type(t) == str else "" for t in camping_data['tag']]

        for kw in ['#ë´„ ', '#ì—¬ë¦„ ', '#ê°€ì„', '#ê°€ì„ ', '#ê²¨ìš¸', 'ë´„ ', 'ì—¬ë¦„ ', 'ê°€ì„ ', 'ê²¨ìš¸',]:
            camping_data['tag'] = [t.replace(kw, "") if type(t) == str else "" for t in camping_data['tag']]

        camping_data["tag"] = camping_data["tag"].str.replace(" ", "")
        camping_data_a = camping_data["tag"].str.split("#").apply(pd.Series).loc[:, 1:]
        camping_data_b = pd.get_dummies(camping_data_a.stack()).reset_index().groupby("level_0").sum().drop("level_1", 1)

        main_df = pd.DataFrame()
        
        for i in range(len(camping_data_b)):
            main_df = pd.concat([pd.DataFrame(camping_data_b.values[i] * lookup["main_cat"].T), main_df], 1)

        main_df = main_df.T.reset_index(drop=True)
        main_df = pd.get_dummies(main_df.stack()).reset_index().groupby("level_0").sum().drop("level_1", 1)
        main_df = main_df.iloc[:,1:]
        main_df.index = camping_data_b.index
        last_df  = pd.concat([camping_data_b, main_df], 1)
        last_df[last_df > 1] = 1
        last_df['index']= last_df.index
        algo_search_df = pd.merge(camping_data, last_df, how="left", left_on = 'place_id', right_on='index').drop("index", 1)
        algo_search_df = algo_search_df.rename(columns={'ê°€ì¡±' : 'with_family_s',
                                            'ê³„ê³¡ì˜†' : 'valley_s',
                                            'ê¹¨ë—í•œ' : 'clean_s',
                                            'ë‘˜ë ˆê¸¸' : 'trail_s',
                                            'ë¬¸í™”ìœ ì ' : 'cultural_s',
                                            'ë¬¼ë†€ì´í•˜ê¸°ì¢‹ì€' : 'waterplay_s',
                                            'ë¬¼ë§‘ì€' : 'pure_water_s',
                                            'ë°”ë‹¤ê°€ë³´ì´ëŠ”' : 'ocean_s',
                                            'ë°˜ë ¤ê²¬' : 'with_pet_s',
                                            'ë³„ë³´ê¸°ì¢‹ì€' : 'star_s',
                                            'ì‚¬ì´íŠ¸ê°„ê²©ì´ë„“ì€' : 'spacious_s',
                                            'ìƒíƒœêµìœ¡' : 'ecological_s',
                                            'ìˆ˜ì˜ì¥ìˆëŠ”' : 'pool_s',
                                            'ì•„ì´ë“¤ë†€ê¸°ì¢‹ì€' : 'with_child_s',
                                            'ì˜¨ìˆ˜ì˜ë‚˜ì˜¤ëŠ”' : 'hot_water_s',
                                            'ìµìŠ¤íŠ¸ë¦¼' : 'extreme_s',
                                            'ìì „ê±°íƒ€ê¸°ì¢‹ì€' : 'bicycle_s',
                                            'ì°¨ëŒ€ê¸°í¸í•œ' : 'parking_s',
                                            'ì¶•ì œ' : 'festival_s',
                                            'ì»¤í”Œ' : 'with_couple_s', 
                                            'íë§' : 'healing_s',
                                            'ì•¡í‹°ë¹„í‹°' : 'activity_m',
                                            'ìì—°/íë§' : 'nature_m',
                                            'ì¦ê¸¸ê±°ë¦¬' : 'fun_m',
                                            'ì¾Œì /í¸ë¦¬' : 'comfort_m',
                                            'í•¨ê»˜' : 'together_m'})
        
        return algo_search_df

    def search_table(self, algo_search_df): 
        search_df = algo_search_df.drop(['place_id','animal_cmg', 'ì¬ë¯¸ìˆëŠ”', 'ì¹œì ˆí•œ', 'ì—¬ìœ ìˆëŠ”', 'ê·¸ëŠ˜ì´ë§ì€'],1)
        return search_df


class Query:   
    # db cursor ìƒì„±
    def connect_sql(self, IP, DB, PW):
        engine = create_engine(f"mysql+mysqldb://root:{PW}@{IP}/{DB}")

        conn = engine.connect()

        mydb = pymysql.connect(
            user='root',
            passwd=PW,
            host=IP,
            db=DB,
            charset='utf8',
        )
        cursor = mydb.cursor(pymysql.cursors.DictCursor)

        return cursor, engine, mydb

    # dbì— ì €ì¥
    def save_sql(self, cursor, engine, db, data, table, option):
        data.to_sql(name=table, con=engine, if_exists=option, index=False)


if __name__ == '__main__':
    IP = " "
    DB = " "
    PW = " "

    gocamp = Gocamp()
    sgg = Sigungucode()
    sub = PlaceSubTable()
    algo = AlgorithmTable()
    sql = Query()
    cursor, engine, db = sql.connect_sql(IP, DB, PW)
    
    # gocamp crawling
    list_df = gocamp.fetch_link_list()
    df = gocamp.fetch_link_details(list_df)
    camp_details = gocamp.make_camp_crawling(df)
    
    # gocamp API
    df = gocamp.gocampingAPI()
    # sigungucode
    camp_api_df = sgg.make_sigungucode(df)
    camp = gocamp.make_camp_api(camp_api_df)
    
    # crawling and API files merge for the details
    camp_df = gocamp.merge_data(camp, camp_details)
    
    # camp info append insert to place table
    truncate_qry = ('''
        TRUNCATE TABLE place;
    ''')
    cursor.execute(truncate_qry)
    
    place_df = sub.place_table(camp_df)
    sql.save_sql(cursor, engine, db,  place_df, "place", "append")

    # conveniece table insert
    convenience_df = sub.convenience_table(camp_df)
    sql.save_sql(cursor, engine, db, convenience_df, "convenience", "append")

    # operation table insert
    operation_df = sub.operation_table(camp_df)
    sql.save_sql(cursor, engine, db, operation_df, "operation", "append")

    # variety table insert
    variety_df = sub.variety_table(camp_df)
    sql.save_sql(cursor, engine, db, variety_df, "variety", "append")

    #safety table insert
    safety_df = sub.safety_table(camp_df)
    sql.save_sql(cursor, engine, db, safety_df, "safety", "append")

    #search table insert
    algo_search_df = algo.tag_stack(camp_df)
    search_df = algo.search_table(algo_search_df)
    sql.save_sql(cursor, engine, db, search_df, "search", "append")


    db.close()